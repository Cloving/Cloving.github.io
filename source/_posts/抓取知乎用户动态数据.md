---
title: 抓取知乎用户动态数据
layout: post
date: 2018-11-20 19:58:07
description: 知乎爬虫
categories: 
- 数据抓取
- 知乎
tags:
- Python
- ajax
- MongoDB
cover: https://cdn.jsdelivr.net/gh/Cloving/Atlas-Github/blog/CoverPicture/bg_6.jpeg
---

<br />
## 一、简介
打开知乎某个用户的主页可以看到该用户赞同回答、关注专栏、关注问题等行为数据。本文利用Python的requests库抓取知乎用户行为数据并存入MongoDB数据库中。
<br/>
## 二、分析数据加载方式
1. 打开网页后向下拉取可以观察到行为数据并不是一次加载完，而是随着用户的浏览进度逐步加载，考虑可能是ajax的形式。
2. 之后打开Chrome控制台分析网络选项，查看XHR(XMLHttpRequest)类型的文件可以观察出收到的响应是json数据，其中包含了用户行为数据的相关信息

![图1](https://cdn.jsdelivr.net/gh/Cloving/Atlas-Github/blog/notePicture/抓取知乎用户动态数据/知乎分析1.png)

所以首先需要请求到网站返回的json数据，然后对数据进行解析，结构化处理，存入MongoDB中。
<br/>
## 三、代码分析
### 1、初始化变量
```python
  def __init__(self):
    self.user_name = "******"
    self.max_search_counts = **
    self.params = {
      "limit": 7,
      "desktop": "True"
    }
    self.base_url = "https://www.zhihu.com/api/v4/members/"
    self.url = self.base_url + '/' + self.user_name + '/activities?' + urlencode(self.params)

    self.headers = {
      "User-Agent": "Mozilla/5.0 (X11; Linux x86_64)\
                    AppleWebKit/537.36 (KHTML, like Gecko)\
                    Chrome/70.0.3538.77 Safari/537.36",
      "Referer": "https://www.zhihu.com/",
      "x-requested-with": "fetch"
    }
    self.client = MongoClient('127.0.0.1',username='admin',
                        password='******',
                        authSource='admin',
                        authMechanism='SCRAM-SHA-1')
    self.db = self.client["zhihu"]
    self.collection = self.db["zhihuDynamic"]
```

1、`user_name`并不是用户的知乎ID，而是用户的个性化域名。比如知乎小管家的个性化域名为`zhihuadmin`，这可以通过观察用户主页的url获得
2、请求的url就是返回json数据，在控制台的`Network`选项中观察到返回`json`数据的`url`类似于以下形式：
```html
https://www.zhihu.com/api/v4/members/zhihuadmin/activities?limit=7&after_id=1542365521&desktop=True
```
分析组成可以看出`https://www.zhihu.com/api/v4/members/`为通用部分。`zhihuadmin`为用户的个性化域名。?之后是携带的参数
3、抓取知乎的数据必须携带用户代理。

### 2、开始抓取
```Python
def startSearch(self):
  for search_times in range(0, self.max_search_counts):
    json = self.get_Page(self.url)
    try:
      self.url = json.get("paging").get("next")
      print(self.url)
    except Exception as e:
      print("获取下一次请求的链接失败，失败原因：", e)
    results = self.get_Parse(json)
    print("=======================================")
    for result in results:
      self.save_to_mongodb(result)
```
`for`循环控制搜索次数，每次搜索会抓取7条数据即7次动态。之后提取出本次抓取到json数据中的用户动态信息，并更新下一次搜索的url，并将提取出的数据存入MongoDB中

### 3、抓取json数据
```Python
# 获取json数据
def get_Page(self, url):
  try:
    response = requests.get(url, headers=self.headers)
    if response.status_code == 200:
      return response.json()
  except requests.ConnectionError as e:
    print("Error: ", e.args)
```
传入页面的url,返回相应的json数据


### 4、解析json数据

根据传入json数据的格式，提取用户的各项动态
![json数据示意图]( https://cdn.jsdelivr.net/gh/Cloving/Atlas-Github/blog/notePicture/抓取知乎用户动态数据/知乎json.png)

```Python
# 解析json数据
def get_Parse(self, json):
  if json:
    items = json.get('data')
    for item in items:
      zhihu = {}
      action_text = item.get("action_text")
      created_time = item.get("created_time")
      zhihu["操作行为"] = action_text
      zhihu["时间"] = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(created_time))
      if item.get('verb') == "MEMBER_VOTEUP_ARTICLE":
        item_detail =  voteup_article(item.get("target"))
      elif item.get('verb') == "ANSWER_VOTE_UP":
        item_detail = answer_voteUp(item.get("target"))
      elif item.get('verb') == "MEMBER_CREATE_ARTICLE":
        item_detail =  create_article(item.get("target"))
      elif item.get('verb') == "MEMBER_FOLLOW_COLUMN":
        item_detail =  follow_column(item.get('target'))
      elif item.get('verb') == "ANSWER_CREATE":
        item_detail = answer_create(item.get('target'))
      elif item.get('verb') == "QUESTION_FOLLOW":
        item_detail = question_follow(item.get('target'))
      yield dict(zhihu, **item_detail)
```

### 5、将解析出来的数据导入到数据库中
```Python
  # 导入到json数据库中
  def save_to_mongodb(self, result):
    if self.collection.insert_one(result):
      print("Successful save to Mongodb")
```
<br/>
## 四、总结
代码写的并不好，仅作为参考。完整代码: [点这里](https://github.com/Cloving/zhihu-Spider/tree/master/%E7%9F%A5%E4%B9%8E%E7%94%A8%E6%88%B7%E5%8A%A8%E6%80%81)
<br/>
## 参考文献
### 1、[Authentication Examples — PyMongo 3.7.2 documentation](http://api.mongodb.com/python/current/examples/authentication.html)
### 2、[Ajax结果提取 — Python3网络爬虫开发实战](https://germey.gitbooks.io/python3webspider/content/6.3-Ajax%E7%BB%93%E6%9E%9C%E6%8F%90%E5%8F%96.html)
### 3、[知乎小管家 — 知乎](https://www.zhihu.com/people/zhihuadmin/activities)
<br/>
