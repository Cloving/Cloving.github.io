---
title: 抓取网易云音乐榜单
layout: post
date: 2018-12-20 18:33:54
description: 网易云榜单爬虫
categories:
- 数据抓取
- 网易云音乐
tags:
- Python
- MySQL
- Selenium
- 正则表达式
cover: https://cdn.jsdelivr.net/gh/Cloving/Atlas-Github/blog/CoverPicture/bg_10.jpeg
---


## 摘要
本文分别利用`Selenium`自动化测试工具与`requests`库抓取网易云音乐的榜单，包括歌曲名、歌曲时长以及演唱者等信息。`Selenium`仅仅抓取了首个榜单，`requests`抓取了所有榜单。抓取之后将所有数据存入`MySQL`数据库中。

## Selenium抓取单个表单
`Selenium`是一种自动化测试工具，它可以模拟浏览器的行为，所以也可以用于爬虫。下载对应的[驱动](https://sites.google.com/a/chromium.org/chromedriver/downloads)之后，可以调用各种主流浏览器。一般在爬虫的过程因为效率问题并不打开浏览器，而使用无界面的模式。

### 执行过程
#### 1、初始化变量
初始化的过程中包括请求的`url`，请求的数目以及数据库的一些配置。`selenium`使用`Chrome`驱动。
```Python
def __init__(self):
  self.url = "https://music.163.com"
  self.count = 0
  self.host = "127.0.0.1"
  self.user = "root"
  self.password = "******"
  self.db = "spider"
  self.chrome_option = Options()
  self.chrome_option.add_argument('--headless')
  self.DRIVER = webdriver.Chrome(chrome_options=self.chrome_option)
  # The format string is not really a normal Python format string.
  # You must always use %s for all fields.
  self.importSQL = """INSERT INTO NetEaseCloudMusic(ID, musicName, time, singer)
            VALUES (%s, %s, %s, %s)"""
```
#### 2、连接MySQL数据库，并从首页跳转到榜单页
根据初始化的数据库配置信息，连接上数据库删除旧表，创建新表
```python
def connect_mysql(self):
  self.db = pymysql.connect(host=self.host, user=self.user, passwd=self.password, db=self.db)
  print("成功连接Mysql数据库")
  self.cursor = self.db.cursor()
  self.cursor.execute("DROP TABLE IF EXISTS NetEaseCloudMusic")
  # 如果使用单引号，需要
  sql = '''CREATE TABLE NetEaseCloudMusic(
          ID INT NOT NULL,
          musicName LONGTEXT,
          time LONGTEXT,
          singer LONGTEXT
          )'''
  self.cursor.execute(sql)
```

榜单信息的url为`https://music.163.com/#/discover/toplist`，所以需要从首页跳转。跳转之后观察到榜单信息并不是直接加载在网页中，而是在页面的`iframe`标签中，所以需要跳转到子`iframe`拿到数据
```python
def jump_targetpage(self):
  # 其中 driver.get 方法会打开请求的URL，
  # WebDriver 会等待页面完全加载完成之后才会返回，
  # 即程序会等待页面的所有内容加载完成，JS渲染完毕之后才继续往下执行。
  self.DRIVER.get(self.url)
  self.DRIVER.find_element_by_xpath('//ul[@class="nav"]/li[2]').click()
  try:
    self.firstChild_iframe = self.DRIVER.find_element_by_id("g_iframe")
  except Exception as e:
    print("Get iframe Failed: ", e)
  sleep(2)
  self.DRIVER.switch_to.frame(self.firstChild_iframe)
  table = self.DRIVER.find_element_by_tag_name('table')
  self.songList = table.find_elements_by_xpath('tbody/tr')
  return self.songList
```

#### 3、提取数据并保存到数据库中
使用`xpath`来提取歌曲名称、播放时长、演唱者等信息。
```Python
def start_search(self, song):    
  songChildList = []
  songChildList.append(song.find_element_by_xpath('td[2]//b').get_attribute('title'))
  songChildList.append(song.find_element_by_xpath('td[3]//span[@class="u-dur "]').text)
  songChildList.append(song.find_element_by_xpath('td[last()]//span').get_attribute('title'))
  return songChildList
```

保存到数据库中，并记录每次导入的条数
```python
def import_data(self, data):
  try:
    self.cursor.execute(self.importSQL, (self.count+1, data[0], data[1], data[2]))
    self.db.commit()
    self.count += 1
    print("成功导入第{count}条数据".format(count=self.count))
  except Exception as e:
    print('导入数据失败： ', e)
    self.db.rollback()
```
### 小结
这里并不介绍`Selenium`的具体使用方式，侧重于抓取的过程描述以及如何实现这一过程的简单代码示例。完整代码：[Selenium抓取单个表单](https://github.com/Cloving/NetEase-Spider/blob/master/%E7%BD%91%E6%98%93%E4%BA%91%E9%9F%B3%E4%B9%90%E6%A6%9C%E5%8D%95/selenium_NetEaseMusic.py)

## requests抓取所有表单
分析网易云音乐榜单页面的网络请求，如图所示：
![默认页面请求](https://cdn.jsdelivr.net/gh/Cloving/Atlas-Github/blog/notePicture/抓取网易云音乐榜单/默认页面请求.jpg)

从默认页面`https://music.163.com/#/discover/toplist`请求的响应信息可以看到各类榜单的标题以及`href`属性信息。事实上，通过观察浏览器地址栏的`url`可以看出`href`的属性值位于`#`之后，所以这是一个`fragment`，访问网站之后可以直接到达页面的指定位置。我们需要提取出每个榜单的`href`属性信息，再逐个请求这些`url`，通过返回的响应分析出每个`url`中包含的歌曲信息，再逐个保存到数据库中，并统计总的数据量。

### 请求过程
初始化变量以及连接数据库的部分在使用`selenium`请求中已经介绍过，大同小异。此处不再过多介绍，在文章结尾处会给出源代码的链接。
关于发起请求的函数部分，由于请求的`url`包括初始的`url`以及每个榜单的`url`，所以在请求函数中考虑使用可变数量的参数，如果没有传入其他参数则使用初始化的`url`，否则使用传入的`url`。过程如下：

``` python
def start_request(self, *arg):
  # 向给定的url请求数据，如果arg为空，请求原始的url，否则请求arg
  url = arg if arg else self.url
  if isinstance(url, tuple):
    # arg是元组类型
    request_url = url[0]
  else:
    request_url = url
  try:
    response = requests.get(request_url, headers=self.header)
    if response.status_code == 200:
      print("请求成功")
    return response
  except Exception as e:
    print("请求失败，失败原因：", e)
```

### 处理原始请求的数据
对原始的`url`发送请求时，使用`正则表达式`提取所有榜单的`href`属性，再与原始的`url`进行拼接（因为拼接的`url`即使不带有`#`也会自动跳转，所以代码中并未添加`#`），得到并请求单个榜单的`url`。
单个榜单的`url`中并不能够找到规则的歌曲数据。通过观察发现所有歌曲数据都存在其中一个`textarea`的标签中，标签中的数据为`json`格式，所以需要利用这些`json`数据提取歌曲信息。这里通过`正则表达式`将其提取出来。


![单个榜单请求](https://cdn.jsdelivr.net/gh/Cloving/Atlas-Github/blog/notePicture/抓取网易云音乐榜单/单个榜单请求.png)

``` python
def process_data(self, source_response):
  # 处理原始url的请求，提取并处理每个榜单的url
  pattern = re.compile('<p class="name"><a href="(.*?)" class="s-fc0">')
  lists_link = pattern.findall(source_response.text)
  for list_link in lists_link:
    url = parse.urljoin(self.url, list_link)
    list_response = self.start_request(url)
    json_datas = self.process_jsondata(list_response)
    self.process_musicdata(json_datas)

def process_jsondata(self, response):
  # 提取每个榜单的json数据 
  pattern = re.compile('.*?id="song-list-pre-data".*?>(.*?)</textarea>')
  match = pattern.search(response.text)
  json_datas = json.loads(match.group(1))
  with open('data.json', 'wb') as f:
    f.write(match.group(1).encode('utf8'))
  return json_datas
```

### 处理包含歌曲信息的json数据
歌曲名与演唱者都可以直接从`json`中直接方便的读取到，但是歌曲的时长并不能从数据中直接看出来。所以回到原始榜单的响应中寻找信息，发现了可能是控制歌曲时长显示的部分，如图所示：

![歌曲时长](https://cdn.jsdelivr.net/gh/Cloving/Atlas-Github/blog/notePicture/抓取网易云音乐榜单/歌曲时长.png)

以下语句为控制歌曲时长显示的代码：
``` javascript
${dur2time(x.duration/1000)}
```

实际上我并没有在所有网络请求中找到有关`dur2time`的信息（也可能是我还不知道怎样分析这一部分）。但在`json`数据中存在`duration`的`key`，所以我认为`duration`的数值可能会通过某种转换，显示为歌曲时长。将`duration`的值除以1000与页面中显示的歌曲时长对应起来，试着找到其中的规律。

- 179.2 &nbsp;&nbsp;  02：59
- 216 &nbsp;&nbsp;  03：36

从以上的对应关系中基本上可以判断`duration`除以1000即是歌曲时长的秒数。
到此可以便可以对歌曲的数据进行提取。过程如下所示：

```python
def process_musicdata(self, json_datas):
  # 处理每个榜单的json数据
  for json_data in json_datas:
    music_name = json_data.get("name")
    play_time = self.process_playtime(json_data.get("duration")/1000)
    singers = ''
    for artist in json_data.get("artists"):
      singers += '/' + artist.get("name")
    singers = singers.replace('/', '', 1)
    data = [music_name, play_time, singers]
    self.save_data(data)

def process_playtime(self, duration):
  # 处理播放时间数据
  minutes = math.floor(duration/60)
  seconds = math.floor(duration%60)
  minutes = minutes if minutes >= 10 else '0'+str(minutes)
  seconds = seconds if seconds >= 10 else '0'+str(seconds)
  return '%s:%s' % (minutes, seconds)
```

### 保存到数据库中
每次处理一个榜单的响应便保存到数据库中。本次提取的所有歌曲榜单，共有`1614`条音乐数据
```python
def save_data(self, data):
  # 保存数据到数据库
  try:
    self.cursor.execute(self.importSQL, (self.count, data[0],data[1],data[2]))
    self.db.commit()
    print("成功导入第{count}条数据".format(count=self.count))
    self.count += 1
  except Exception as e:
    print("导入数据失败，失败原因：", e)
    self.db.rollback()
```

## 总结
本文分别使用了`Selenium`与`requests`两种方式抓取音乐榜单数据。实际测试中`Selenium`的抓取速度较慢，但是过程相对简单。使用`requests`请求过程稍显复杂，但是速度较快。完整代码：[抓取网易云音乐榜单](https://github.com/Cloving/NetEase-Spider/tree/master/%E7%BD%91%E6%98%93%E4%BA%91%E9%9F%B3%E4%B9%90%E6%A6%9C%E5%8D%95)


## 参考文献
[1、Selenium with Python Selenium Python Bindings 2 documentation](https://selenium-python.readthedocs.io/)
[2、Getting Started with Headless Chrome | Web | Google Developers](https://developers.google.com/web/updates/2017/04/headless-chrome)
[3、2. 快速入门 Selenium-Python中文文档 2 documentation](https://selenium-python-zh.readthedocs.io/en/latest/getting-started.html)
[4、python3 urllib.parse.urljoin（）用法 - 余安 - CSDN博客](https://blog.csdn.net/mycms5/article/details/76902041)
[5、20.7. urllib.parse — Parse URLs into components &mdash; Python v3.2.6 documentation](https://docs.python.org/3.2/library/urllib.parse.html)


